# llm-inference-benchmarks-gh200
Production-ready benchmarking suite: compare Hugging Face LLM inference on NVIDIA GH200 between PyTorch, JAX/Flax, and vLLM. Unified latency, throughput, and memory logging.  Designed for LLM system and ML acceleration with clean config and reproducible scripts.
